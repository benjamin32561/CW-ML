{"cells":[{"cell_type":"code","source":["!rm -r sample_data\n","\n","!pip install wandb\n","!pip install torchmetrics\n","\n","!git clone https://github.com/benjamin32561/Cloud-Wise-ML.git"],"metadata":{"id":"PgjDpgm_um1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"q3irlkJzvsas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","sys.path.append(os.path.abspath('/content/Cloud-Wise-ML/training/Classifier'))"],"metadata":{"id":"D1R0mFI4x_ZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbiLeyBbt5sb"},"outputs":[],"source":["import torch\n","import wandb\n","import pandas as pd\n","import numpy as np\n","import common_constants as cc\n","import common_functions as cf\n","from torch.optim import Adam, SGD\n","from torch.utils.data import DataLoader\n","from copy import deepcopy\n","from random import randint\n","from torchmetrics.classification import BinaryPrecision, BinaryRecall, BinaryAccuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WaaG-Hh5C3C"},"outputs":[],"source":["class LinearAutoEncoder(torch.nn.Module):\n","\tdef __init__(self):\n","\t\tsuper().__init__()\n","\t\t\n","\t\tself.encoder = torch.nn.Sequential()\n","\t\t\n","\t\tself.decoder = torch.nn.Sequential()\n","\n","\tdef forward(self, x):\n","\t\tx = torch.flatten(x, start_dim=1)\n","\t\tx = self.encoder(x)\n","\t\tx = self.decoder(x)\n","\t\treturn x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cv8d5Snt5sg"},"outputs":[],"source":["class LinearClassifier(torch.nn.Module):\n","\tdef __init__(self,input_layer_size,backbone_location=None):\n","\t\tsuper().__init__()\n","\t\t\n","\t\tif backbone_location==None:\n","\t\t\tself.backbone = torch.nn.Sequential(\n","\t\t\t\ttorch.nn.Linear(input_layer_size, 1024),\n","\t\t\t\ttorch.nn.ReLU(),\n","\t\t\t\ttorch.nn.Linear(1024, 512),\n","\t\t\t\ttorch.nn.ReLU(),\n","\t\t\t)\n","\t\telse:\n","\t\t\tself.backbone = torch.load(backbone_location).encoder\n","\t\t\n","\t\tself.classification_head = torch.nn.Sequential(\n","\t\t\ttorch.nn.Linear(self.GetLastLayerOutput(), 128),\n","\t\t\ttorch.nn.ReLU(),\n","\t\t\t# torch.nn.Linear(256, 128),\n","\t\t\t# torch.nn.ReLU(),\n","\t\t\t# torch.nn.Linear(256, 64),\n","\t\t\t# torch.nn.ReLU(),\n","\t\t\ttorch.nn.Linear(128, 1),\n","\t\t\ttorch.nn.Sigmoid()\n","\t\t)\n","\n","\tdef BackboneMode(self,train=False):\n","\t\tself.backbone.train(train)\n","\n","\tdef forward(self, x):\n","\t\tx = torch.flatten(x, start_dim=1)\n","\t\tx = self.backbone(x)\n","\t\tx = self.classification_head(x)\n","\t\treturn x\n","\t\n","\tdef GetLastLayerOutput(self):\n","\t\tlayers = self.backbone.children()\n","\t\tn_layers = 0\n","\t\tfor layer in layers:\n","\t\t\tn_layers+=1\n","\n","\t\tlayers = self.backbone.children()\n","\t\tidx = 0\n","\t\tfor layer in layers:\n","\t\t\tif idx==n_layers-2:\n","\t\t\t\treturn layer.out_features\n","\t\t\tidx+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31mVROOgt5se"},"outputs":[],"source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","WANDB_PROJECT_NAME = \"Classifier\"\n","RUN_NAME = \"2_3\"\n","\n","INPUT_LAYER_SIZE = 2031\n","\n","EPOCHS = 20\n","START_FROM = 0\n","\n","SHOW_N_TESTS = 10\n","\n","TRAIN_BATCH_SIZE = 1\n","TEST_BATCH_SIZE = 4\n","\n","BACKBONE_LOCATION = \"/content/drive/MyDrive/ML/training/AutoEncoder/LinearModel/2/models/best.pt\" #None"]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/ML/accident_or_not_dataset /content/accident_or_not_dataset"],"metadata":{"id":"F9BN5WDr31tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/Cloud-Wise-ML/data_analysis\n","\n","!python save_xlsx_paths.py --folder_class_dict_file /content/Cloud-Wise-ML/training/Classifier/folder_class_dict.txt --txt_file_location /content/record_class.txt\n","\n","!python split_txt.py --txt_file_location /content/record_class.txt"],"metadata":{"id":"bjIzzobE4QX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aVaU5xOezKm6"},"outputs":[],"source":["cf.CreatePath(cc.MODELS_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbdjGmeOzKnB"},"outputs":[],"source":["wandb.init(project=WANDB_PROJECT_NAME,name=RUN_NAME) #d2ea8beb067a044208ad55aa1b7e888b30b7bf22"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl6V1nVDzKm-"},"outputs":[],"source":["train_dataset = cf.ClassifierAcceleratorDataset(cc.TRAIN_TXT_PATH)\n","train_dataloader = DataLoader(train_dataset,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n","test_dataset = cf.ClassifierAcceleratorDataset(cc.TEST_TXT_PATH)\n","test_dataloader = DataLoader(test_dataset,batch_size=TEST_BATCH_SIZE,shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gD2nQJkot5sl"},"outputs":[],"source":["sub_project_path = os.path.join(cc.MODELS_PATH,'LinearModel')\n","cf.CreatePath(sub_project_path)\n","sub_model_path = os.path.join(sub_project_path,RUN_NAME)\n","cf.CreatePath(sub_model_path)\n","models_path = os.path.join(sub_model_path,'models')\n","cf.CreatePath(models_path)\n","\n","model = LinearClassifier(INPUT_LAYER_SIZE,BACKBONE_LOCATION).to(DEVICE)\n","loss_func = torch.nn.BCELoss()\n","optimizer = Adam(model.parameters()) #SGD(model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIEk2R9tt5sn"},"outputs":[],"source":["best_val = -1\n","best_model = -1\n","precision = BinaryPrecision().to(DEVICE)\n","recall = BinaryRecall().to(DEVICE)\n","accuracy = BinaryAccuracy().to(DEVICE)\n","for epoch in range(START_FROM, EPOCHS):\n","    #train\n","    model.train()\n","    model.BackboneMode()\n","    epoch_data = []\n","    n_batches = len(train_dataloader)\n","    for idx, data in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        x,y = data\n","        x = x.to(torch.float32).to(DEVICE)\n","        y = y.to(torch.float32).to(DEVICE)\n","\n","        prediction = model(x)\n","    \n","        loss = loss_func(prediction,y)\n","        epoch_data.append(float(loss))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(\"\",end='\\rEpoch: {}/{} | Batch: {}/{} | loss: {}'.format(epoch,EPOCHS,idx,n_batches,np.mean(epoch_data)))\n","    epoch_loss = np.mean(epoch_data)\n","    del epoch_data\n","\n","    #evaluating\n","    model.eval()\n","    optimizer.zero_grad()\n","    val_data = []\n","    class_labels = torch.tensor([]).to(DEVICE)\n","    class_predictions = torch.tensor([]).to(DEVICE)\n","    for idx, data in enumerate(test_dataloader):\n","        x,y = data\n","        x = x.to(torch.float32).to(DEVICE)\n","        y = y.to(torch.float32).to(DEVICE)\n","\n","        prediction = model(x)\n","        rounded_predictions = torch.round(prediction)\n","\n","        class_labels = torch.cat((class_labels,y[:,0]))\n","        class_predictions = torch.cat((class_predictions,rounded_predictions[:,0]))\n","\n","        loss = loss_func(prediction,y)\n","        val_data.append(float(loss))\n","        \n","    val_loss = np.mean(val_data)\n","    val_pre = float(precision(class_predictions,class_labels)) #tp/(tp+fp)\n","    val_rec = float(recall(class_predictions,class_labels)) #tp/(tp+fn)\n","    val_acc = float(accuracy(class_predictions,class_labels)) #n_times_correct/n_gusses\n","    del val_data\n","\n","    print('\\rEpoch: {}/{} | train_loss: {} | val_loss: {} | val_acc: {} | val_per: {} | val_rec: {}\\n'.format(epoch,EPOCHS,epoch_loss,val_loss,val_acc,val_pre,val_rec))\n","\n","    #updating best model so far\n","    val_met = np.mean([val_acc,val_pre,val_rec])\n","    if best_val==-1 or best_val<=val_met:\n","      best_val=val_met\n","      best_model = deepcopy(model)\n","\n","    # wandb.log({\n","    #     \"epoch_loss\":epoch_loss,\n","    #     \"epoch_val_loss\":val_loss,\n","    #     \"epoch_val_acc\":val_acc,\n","    #     \"epoch_val_per\":val_pre,\n","    #     \"epoch_val_rec\":val_rec,\n","    #     \"epoch_val_metrics_avg\":val_met,\n","    # },sync=True,step=epoch)\n","\n","last_path = os.path.join(models_path,'last.pt')\n","#torch.save(model,last_path)\n","best_path = os.path.join(models_path,'best.pt')\n","#torch.save(best_model,best_path)\n","\n","print(\"max validation metrics avg: {}\".format(best_val))"]},{"cell_type":"code","source":["model = torch.load(os.path.join(models_path,'best.pt'))"],"metadata":{"id":"bs1L6EIXackb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jlt45djTt5so"},"outputs":[],"source":["n_test_sample = len(test_dataset)\n","\n","for show_i in range(SHOW_N_TESTS):\n","  idx = randint(0,n_test_sample-1)\n","\n","  df,class_label = test_dataset.__getitem__(idx,True)\n","\n","  model_input = torch.tensor(df.to_numpy()[:,:-1]).unsqueeze(0).to(torch.float32).to(DEVICE)\n","\n","  prediction = model(model_input)\n","\n","  gt_path = os.path.join(sub_model_path,\"{}_GT_{}_PRED_{}.jpg\".format(show_i,round(float(prediction)),int(class_label)))\n","  cf.PlotRecordData(df,False,False,False,gt_path,False)"]},{"cell_type":"markdown","source":["Saving model as ONNX"],"metadata":{"id":"jylRgDo1d_h1"}},{"cell_type":"code","source":["x,_ = test_dataset[0]\n","x = np.expand_dims(x, axis=0)\n","dummy_input = torch.randn(x.shape).to(DEVICE)\n","onnx_path = os.path.join(models_path,'model.onnx')"],"metadata":{"id":"oekiJD_CadRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval() \n","\n","# Export the model   \n","torch.onnx.export(model,         # model being run \n","      dummy_input,       # model input (or a tuple for multiple inputs) \n","      onnx_path,       # where to save the model  \n","      export_params=True,  # store the trained parameter weights inside the model file \n","      opset_version=10,    # the ONNX version to export the model to \n","      do_constant_folding=True,  # whether to execute constant folding for optimization \n","      input_names = ['modelInput'],   # the model's input names \n","      output_names = ['modelOutput'], # the model's output names \n","      dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n","                            'modelOutput' : {0 : 'batch_size'}})"],"metadata":{"id":"M1L23AuVcbLF"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7dac217b36b31e0009f5a4cd7642172bea26f3d46fec2031bdcc95400234d29f"}},"colab":{"provenance":[],"private_outputs":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}