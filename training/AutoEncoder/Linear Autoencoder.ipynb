{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import common_constants as cc\n",
    "import common_functions as cf\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT_NAME = \"AutoEncoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreatePath(cc.MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\tself.encoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(677*3, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 64),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(64, 32),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.decoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(32, 64),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(64, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 677*3)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = torch.flatten(x, start_dim=1)\n",
    "\t\tencoded = self.encoder(x)\n",
    "\t\tdecoded = self.decoder(encoded)\n",
    "\t\treturn decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cf.AEAcceleratorDataset(cc.TRAIN_TXT_PATH)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=cc.TRAIN_BATCH_SIZE,shuffle=False)\n",
    "test_dataset = cf.AEAcceleratorDataset(cc.TEST_TXT_PATH)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=cc.TEST_BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=WANDB_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_project_path = os.path.join(cc.MODELS_PATH,'LinearModel')\n",
    "CreatePath(sub_project_path)\n",
    "models_path = os.path.join(sub_project_path,'models')\n",
    "CreatePath(models_path)\n",
    "\n",
    "model = LinearAutoEncoder()\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = Adam(model.parameters()) #SGD(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = -1\n",
    "best_val_idx = -1\n",
    "for epoch in range(cc.EPOCHS):\n",
    "    #train\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    n_batches = len(train_dataloader)\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(torch.float32).to(DEVICE)\n",
    "        flattned_data = torch.flatten(data, start_dim=1)\n",
    "\n",
    "        prediction = model(data)\n",
    "    \n",
    "        loss = loss_func(prediction,flattned_data)\n",
    "        epoch_loss.append(float(loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"\",end='\\rEpoch: {}/{} | Batch: {}/{} | loss: {}'.format(epoch,cc.EPOCHS,idx,n_batches,np.mean(epoch_loss)))\n",
    "    epoch_final_loss = np.mean(epoch_loss)\n",
    "    del epoch_loss\n",
    "\n",
    "    #evaluating\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    validation_loss = []\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        data = data.to(torch.float32).to(DEVICE)\n",
    "        flattned_data = torch.flatten(data, start_dim=1)\n",
    "\n",
    "        prediction = model(data)\n",
    "        \n",
    "        loss = loss_func(prediction,flattned_data)\n",
    "        validation_loss.append(float(loss))\n",
    "    validation_final_loss = np.mean(validation_loss)\n",
    "    del validation_loss\n",
    "    print('\\nEpoch: {}/{} | train_loss: {} | val_loss: {}\\n'.format(epoch,cc.EPOCHS,epoch_final_loss,validation_final_loss))\n",
    "\n",
    "    save_model_at = os.path.join(models_path,'epoch_{}.pt'.format(epoch))\n",
    "    torch.save(model,save_model_at)\n",
    "\n",
    "    # wandb.log({\n",
    "    #     \"epoch_loss\":epoch_final_loss,\n",
    "    #     \"epoch_validation_loss\":validation_final_loss\n",
    "    # },sync=True)\n",
    "\n",
    "    if best_val_idx==-1 or best_val>validation_final_loss:\n",
    "        best_val=validation_final_loss\n",
    "        best_val_idx=epoch\n",
    "\n",
    "best_path = os.path.join(models_path,'epoch_{}.pt'.format(best_val_idx))\n",
    "new_best_path = os.path.join(models_path,'best.pt')\n",
    "if os.path.exists(new_best_path):\n",
    "    os.remove(new_best_path)\n",
    "os.rename(best_path,new_best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(models_path,'epoch_0.pt'))\n",
    "n_test_sample = len(test_dataset)\n",
    "\n",
    "first = True\n",
    "last_pred = None\n",
    "for show_i in range(cc.SHOW_N_TESTS):\n",
    "    idx = randint(0,n_test_sample-1)\n",
    "\n",
    "    df = test_dataset.__getitem__(idx,True)\n",
    "\n",
    "    model_input = torch.flatten(torch.tensor(df.to_numpy()[:,:-1]).unsqueeze(0), start_dim=1).to(torch.float32).to(DEVICE)\n",
    "\n",
    "    prediction = model(model_input)\n",
    "\n",
    "    prediction = prediction.view(1,677,3).detach().numpy()[0]\n",
    "    if first:\n",
    "        first = False\n",
    "        last_pred=prediction\n",
    "    else:\n",
    "        print((prediction==last_pred).all())\n",
    "        last_pred = prediction\n",
    "\n",
    "    new_df_data = {}\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if i==3:\n",
    "            new_df_data[col] = df[col]\n",
    "            break\n",
    "        new_df_data[col] = prediction[:,i]\n",
    "\n",
    "    new_df = pd.DataFrame(new_df_data)\n",
    "\n",
    "    gt_path = os.path.join(sub_project_path,\"GT_{}.jpg\".format(show_i))\n",
    "    cf.PlotRecordData(df,False,False,False,gt_path,False)\n",
    "    pred_path = os.path.join(sub_project_path,\"Prediction_{}.jpg\".format(show_i))\n",
    "    cf.PlotRecordData(new_df,False,False,False,pred_path,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.encoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv1d(3, 8,kernel_size=10, stride=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv1d(8, 16,kernel_size=10, stride=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv1d(16, 32,kernel_size=10, stride=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv1d(32, 64,kernel_size=4, stride=1)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.decoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.ConvTranspose1d(64, 32,kernel_size=4, stride=1),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.ConvTranspose1d(32, 16,kernel_size=10, stride=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.ConvTranspose1d(16, 8,kernel_size=10, stride=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.ConvTranspose1d(8, 3,kernel_size=6, stride=5,padding=2,dilation=7),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tencoded = self.encoder(x)\n",
    "\t\tdecoded = self.decoder(encoded)\n",
    "\t\treturn decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = torch.permute(data,(0,2,1)).to(torch.float32).to(DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dac217b36b31e0009f5a4cd7642172bea26f3d46fec2031bdcc95400234d29f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
